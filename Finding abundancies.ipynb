{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "sage"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as lg\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "sage"
    }
   },
   "outputs": [],
   "source": [
    "G=nx.read_weighted_edgelist('Tortoise.txt') # Load in a file\n",
    "A=nx.to_numpy_array(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "sage"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Graph.adjacency of <networkx.classes.graph.Graph object at 0x7f0cb3600b50>>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.adjacency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "sage"
    }
   },
   "outputs": [],
   "source": [
    "def freqG(A):\n",
    "    n = len(A) # nodes\n",
    "    e = np.ones(n)\n",
    "    k = A@e # degrees.\n",
    "    m = np.sum(k)/2 # edges\n",
    "    Lambda, Q = lg.eigh(A)\n",
    "    # A number of matrices/vectors we'll need in our computations\n",
    "    A2 = A@A \n",
    "    A3 = A2@A\n",
    "    A2a = A2*A\n",
    "    A2b = A2 - np.diag(k)\n",
    "    F10s = sum(A2b*(A2b-1))/2\n",
    "    t = np.diag(A3)/2\n",
    "    tk = t*(k-2)\n",
    "    kk = k*(k-1)\n",
    "    # The fragments F1...F15\n",
    "    P2 = sum(kk/2)\n",
    "    C3 = sum(t)/3\n",
    "    P3 = (k-1).T@A@(k-1)/2-C3*3 \n",
    "    S13 = kk.T@(k-2)/6\n",
    "    C4 = (round(np.sum(Lambda**4)) - 4*P2 - 2*m)/8\n",
    "    T31 = sum(tk)\n",
    "    Diamond = sum(sum((A2a)*(A2a-1)))/4\n",
    "    C5 = (round(np.sum(Lambda**5)) - 30*C3 - 10*T31)/10 # Number of C5\n",
    "    Cr = tk.T@(k-3)/2\n",
    "    T41 = (k-2).T@F10s - 2*Diamond\n",
    "    Reindeer = (k-2).T@(A2*A)@(k-2)/2 - 2*Diamond\n",
    "    T32 = t.T@sum(A2b) - 6*C3 - 2*T31 - 4*Diamond\n",
    "    Bowtie = t.T@(t-1)/2-2*Diamond\n",
    "    House = sum(sum(A*A2*A3))/2-9*C3-2*T31-4*Diamond\n",
    "    C6 = (round(np.sum(Lambda**6)) - 2*m - 12*P2 -24*C3 - 6*P3 - 12*S13 - 48*C4 - 36*Diamond - 12*T41 - 24*Bowtie)/12\n",
    "    Count = np.array([P2, C3, P3, S13, C4, T31, Diamond, C5, Cr, T41, Reindeer, T32, Bowtie, House, C6])\n",
    "    return Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "sage"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 does not have enough dimensions (has 0, gufunc core with signature (n?,k),(k,m?)->(n?,m?) requires 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m Count \u001b[38;5;241m=\u001b[39m \u001b[43mfreqG\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(Count)\n",
      "Cell \u001b[0;32mIn [4], line 26\u001b[0m, in \u001b[0;36mfreqG\u001b[0;34m(A)\u001b[0m\n\u001b[1;32m     24\u001b[0m C5 \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mround\u001b[39m(np\u001b[38;5;241m.\u001b[39msum(Lambda\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mInteger(\u001b[38;5;241m5\u001b[39m))) \u001b[38;5;241m-\u001b[39m Integer(\u001b[38;5;241m30\u001b[39m)\u001b[38;5;241m*\u001b[39mC3 \u001b[38;5;241m-\u001b[39m Integer(\u001b[38;5;241m10\u001b[39m)\u001b[38;5;241m*\u001b[39mT31)\u001b[38;5;241m/\u001b[39mInteger(\u001b[38;5;241m10\u001b[39m) \u001b[38;5;66;03m# Number of C5\u001b[39;00m\n\u001b[1;32m     25\u001b[0m Cr \u001b[38;5;241m=\u001b[39m tk\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m@\u001b[39m(k\u001b[38;5;241m-\u001b[39mInteger(\u001b[38;5;241m3\u001b[39m))\u001b[38;5;241m/\u001b[39mInteger(\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m---> 26\u001b[0m T41 \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mInteger\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[38;5;129;43m@F10s\u001b[39;49m \u001b[38;5;241m-\u001b[39m Integer(\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m*\u001b[39mDiamond\n\u001b[1;32m     27\u001b[0m Reindeer \u001b[38;5;241m=\u001b[39m (k\u001b[38;5;241m-\u001b[39mInteger(\u001b[38;5;241m2\u001b[39m))\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m@\u001b[39m(A2\u001b[38;5;241m*\u001b[39mA)\u001b[38;5;241m@\u001b[39m(k\u001b[38;5;241m-\u001b[39mInteger(\u001b[38;5;241m2\u001b[39m))\u001b[38;5;241m/\u001b[39mInteger(\u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m-\u001b[39m Integer(\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m*\u001b[39mDiamond\n\u001b[1;32m     28\u001b[0m T32 \u001b[38;5;241m=\u001b[39m t\u001b[38;5;241m.\u001b[39mT\u001b[38;5;129m@sum\u001b[39m(A2b) \u001b[38;5;241m-\u001b[39m Integer(\u001b[38;5;241m6\u001b[39m)\u001b[38;5;241m*\u001b[39mC3 \u001b[38;5;241m-\u001b[39m Integer(\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m*\u001b[39mT31 \u001b[38;5;241m-\u001b[39m Integer(\u001b[38;5;241m4\u001b[39m)\u001b[38;5;241m*\u001b[39mDiamond\n",
      "\u001b[0;31mValueError\u001b[0m: matmul: Input operand 1 does not have enough dimensions (has 0, gufunc core with signature (n?,k),(k,m?)->(n?,m?) requires 1)"
     ]
    }
   ],
   "source": [
    "Count = freqG(A)\n",
    "print(Count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "vscode": {
     "languageId": "sage"
    }
   },
   "outputs": [],
   "source": [
    "Trials = 50 # Average over at least 50 random graphs\n",
    "CountR = np.zeros(15)\n",
    "n = len(A) # nodes\n",
    "e = np.ones(n)\n",
    "k = A@e # degrees.\n",
    "m = np.sum(k)/2 # edges\n",
    "for i in range(Trials):\n",
    "    R=nx.erdos_renyi_graph(n,2*m/n/(n-1))  # Here we create a random graph\n",
    "    AR=nx.to_numpy_array(R)    # The rest of the loop just makes use of the formulae calculate earlier\n",
    "    f = freqG(AR)\n",
    "    CountR = CountR + f\n",
    "CountR = CountR/Trials\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "vscode": {
     "languageId": "sage"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.11506248 0.46118721 0.21129047 0.29413873 0.45629287 0.56161694\n",
      " 0.77537932 0.47267299 0.6780824  0.55125429 0.63813887 0.60333418\n",
      " 0.80501798 0.75072023 0.48897196]\n"
     ]
    }
   ],
   "source": [
    "abund=(Count-CountR)/(Count+CountR)\n",
    "print(abund)\n",
    "#If abund >.7 then we can call it a motif. If abund <-.5 it's an anti-motif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true,
    "vscode": {
     "languageId": "sage"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  671.    96.  4551.  1805.   397.  2100.   454.  1766.  8151. 10975.\n",
      " 14303. 12826.  1441.  4424.  7966.]\n"
     ]
    }
   ],
   "source": [
    "print(Count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31merror\u001b[0m: \u001b[1mexternally-managed-environment\u001b[0m\r\n",
      "\r\n",
      "\u001b[31m×\u001b[0m This environment is externally managed\r\n",
      "\u001b[31m╰─>\u001b[0m To install Python packages system-wide, try apt install\r\n",
      "\u001b[31m   \u001b[0m python3-xyz, where xyz is the package you are trying to\r\n",
      "\u001b[31m   \u001b[0m install.\r\n",
      "\u001b[31m   \u001b[0m \r\n",
      "\u001b[31m   \u001b[0m If you wish to install a non-Debian-packaged Python package,\r\n",
      "\u001b[31m   \u001b[0m create a virtual environment using python3 -m venv path/to/venv.\r\n",
      "\u001b[31m   \u001b[0m Then use path/to/venv/bin/python and path/to/venv/bin/pip. Make\r\n",
      "\u001b[31m   \u001b[0m sure you have python3-full installed.\r\n",
      "\u001b[31m   \u001b[0m \r\n",
      "\u001b[31m   \u001b[0m If you wish to install a non-Debian packaged Python application,\r\n",
      "\u001b[31m   \u001b[0m it may be easiest to use pipx install xyz, which will manage a\r\n",
      "\u001b[31m   \u001b[0m virtual environment for you. Make sure you have pipx installed.\r\n",
      "\u001b[31m   \u001b[0m \r\n",
      "\u001b[31m   \u001b[0m See /usr/share/doc/python3.11/README.venv for more information.\r\n",
      "\r\n",
      "\u001b[1;35mnote\u001b[0m: If you believe this is a mistake, please contact your Python installation or OS distribution provider. You can override this, at the risk of breaking your Python installation or OS, by passing --break-system-packages.\r\n",
      "\u001b[1;36mhint\u001b[0m: See PEP 668 for the detailed specification.\r\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "vscode": {
     "languageId": "sage"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [8], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinalg\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mlg\u001b[39;00m \u001b[38;5;66;03m# For matrix operations if needed, though NetworkX handles most\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Counter\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcommunity\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mcommunity_louvain\u001b[39;00m \u001b[38;5;66;03m# For Louvain community detection\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# Network Analysis Script for 'Tortoise.txt'\n",
    "# ==============================================================================\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 1. IMPORTS\n",
    "# ------------------------------------------------------------------------------\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy.linalg as lg # For matrix operations if needed, though NetworkX handles most\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import community as community_louvain # For Louvain community detection\n",
    "import os # For file checking\n",
    "\n",
    "print(\"--- Libraries Loaded ---\")\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 2. GLOBAL SETTINGS AND HELPER FUNCTIONS\n",
    "# ------------------------------------------------------------------------------\n",
    "# Matplotlib styles\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 9) # Default figure size, larger for better visibility\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.rcParams['axes.titlesize'] = 18\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "plt.rcParams['legend.fontsize'] = 12\n",
    "plt.rcParams['figure.dpi'] = 100 # Good resolution for saved images\n",
    "\n",
    "# Function to save plots if needed\n",
    "SAVE_PLOTS = False # Set to True to save plots\n",
    "PLOT_DIR = \"network_analysis_plots\"\n",
    "if SAVE_PLOTS and not os.path.exists(PLOT_DIR):\n",
    "    os.makedirs(PLOT_DIR)\n",
    "\n",
    "def save_current_plot(filename):\n",
    "    if SAVE_PLOTS:\n",
    "        filepath = os.path.join(PLOT_DIR, filename)\n",
    "        plt.savefig(filepath, bbox_inches='tight', dpi=150)\n",
    "        print(f\"Plot saved to {filepath}\")\n",
    "\n",
    "print(\"--- Global Settings Initialized ---\")\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 3. LOAD DATA\n",
    "# ------------------------------------------------------------------------------\n",
    "TORTOISE_FILE = \"Tortoise.txt\"\n",
    "\n",
    "# Create a dummy Tortoise.txt file for demonstration if it doesn't exist\n",
    "if not os.path.exists(TORTOISE_FILE):\n",
    "    print(f\"'{TORTOISE_FILE}' not found. Creating a dummy file for demonstration.\")\n",
    "    tortoise_file_content = \"\"\"\n",
    "0\t1\t1\n",
    "0\t2\t1\n",
    "1\t2\t1\n",
    "1\t3\t1\n",
    "2\t3\t1\n",
    "0\t4\t1\n",
    "4\t5\t1\n",
    "0\t6\t1\n",
    "4\t6\t1\n",
    "0\t7\t1\n",
    "0\t8\t1\n",
    "5\t8\t1\n",
    "6\t8\t1\n",
    "7\t8\t1\n",
    "0\t9\t1\n",
    "2\t9\t1\n",
    "3\t9\t1\n",
    "4\t9\t1\n",
    "6\t9\t1\n",
    "8\t9\t1\n",
    "0\t10\t1\n",
    "1\t10\t1\n",
    "2\t10\t1\n",
    "3\t10\t1\n",
    "9\t10\t1\n",
    "0\t11\t1\n",
    "5\t11\t1\n",
    "6\t11\t1\n",
    "1\t12\t1\n",
    "3\t12\t1\n",
    "6\t12\t1\n",
    "10\t12\t1\n",
    "11\t12\t1\n",
    "1\t13\t1\n",
    "12\t13\t1\n",
    "1\t14\t1\n",
    "2\t14\t1\n",
    "3\t14\t1\n",
    "6\t14\t1\n",
    "9\t14\t1\n",
    "10\t14\t1\n",
    "11\t15\t1\n",
    "12\t15\t1\n",
    "5\t16\t1\n",
    "8\t16\t1\n",
    "11\t16\t1\n",
    "3\t17\t1\n",
    "5\t17\t1\n",
    "6\t17\t1\n",
    "8\t17\t1\n",
    "9\t17\t1\n",
    "10\t17\t1\n",
    "11\t17\t1\n",
    "12\t17\t1\n",
    "14\t17\t1\n",
    "15\t17\t1\n",
    "3\t18\t1\n",
    "5\t18\t1\n",
    "6\t18\t1\n",
    "8\t18\t1\n",
    "11\t18\t1\n",
    "15\t18\t1\n",
    "17\t18\t1\n",
    "3\t19\t1\n",
    "6\t19\t1\n",
    "9\t19\t1\n",
    "2\t20\t1\n",
    "6\t20\t1\n",
    "8\t20\t1\n",
    "10\t20\t1\n",
    "17\t20\t1\n",
    "18\t20\t1\n",
    "6\t21\t1\n",
    "17\t21\t1\n",
    "18\t21\t1\n",
    "9\t23\t1\n",
    "22\t23\t1\n",
    "22\t24\t1\n",
    "23\t25\t1\n",
    "24\t25\t1\n",
    "6\t26\t1\n",
    "8\t26\t1\n",
    "9\t26\t1\n",
    "19\t26\t1\n",
    "19\t27\t1\n",
    "26\t27\t1\n",
    "27\t28\t1\n",
    "6\t29\t1\n",
    "9\t29\t1\n",
    "19\t29\t1\n",
    "26\t29\t1\n",
    "27\t29\t1\n",
    "6\t30\t1\n",
    "\"\"\"\n",
    "    with open(TORTOISE_FILE, \"w\") as f:\n",
    "        f.write(tortoise_file_content.strip())\n",
    "\n",
    "# Load the graph using read_weighted_edgelist\n",
    "# It assumes space or tab as delimiter and that nodes are strings.\n",
    "# We need to specify nodetype=int if nodes are integers.\n",
    "try:\n",
    "    G = nx.read_weighted_edgelist(TORTOISE_FILE, nodetype=int)\n",
    "    print(f\"\\nGraph loaded successfully from '{TORTOISE_FILE}'\")\n",
    "    print(f\"Number of nodes: {G.number_of_nodes()}\")\n",
    "    print(f\"Number of edges: {G.number_of_edges()}\")\n",
    "\n",
    "    # Convert to NumPy array (Adjacency Matrix)\n",
    "    # Note: Node labels in G might not be 0-indexed contiguously.\n",
    "    # to_numpy_array handles this by using G.nodes() order or a specified nodelist.\n",
    "    # For simplicity, let's assume nodes are 0 to N-1 or NetworkX handles it.\n",
    "    node_list_for_A = sorted(list(G.nodes())) # Ensure consistent order for A\n",
    "    A = nx.to_numpy_array(G, nodelist=node_list_for_A)\n",
    "    print(f\"Adjacency matrix A created with shape: {A.shape}\")\n",
    "\n",
    "    # Display a few edges from G\n",
    "    print(\"\\nSample Edges from G (first 5):\")\n",
    "    for i, (u, v, data) in enumerate(list(G.edges(data=True))[:5]):\n",
    "        print(f\"({u}, {v}, weight: {data.get('weight', 1)})\")\n",
    "\n",
    "    # Initial plot of the network\n",
    "    plt.figure(figsize=(12, 12)) # Larger size for initial plot\n",
    "    pos_spring = nx.spring_layout(G, seed=42, k=0.7, iterations=50) # k adjusts spacing, iterations for convergence\n",
    "    nx.draw_networkx_nodes(G, pos_spring, node_size=200, node_color='skyblue', alpha=0.9, edgecolors='black', linewidths=0.5)\n",
    "    nx.draw_networkx_edges(G, pos_spring, width=1.2, alpha=0.4, edge_color='gray')\n",
    "    nx.draw_networkx_labels(G, pos_spring, font_size=9, font_weight='bold')\n",
    "    plt.title(\"Initial Visualization of the Tortoise Network\", fontsize=20)\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    save_current_plot(\"00_initial_network_plot.png\")\n",
    "    plt.show()\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: The file '{TORTOISE_FILE}' was not found. Please ensure it's in the correct directory.\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during data loading or initial plotting: {e}\")\n",
    "    exit()\n",
    "\n",
    "print(\"\\n--- Data Loading and Initial Plot Complete ---\")\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 4. DATA DESCRIPTION AND PREVIOUS RESEARCH (TEXTUAL - TO BE FILLED BY USER)\n",
    "# ------------------------------------------------------------------------------\n",
    "print(\"\"\"\n",
    "# ==============================================================================\n",
    "# 4. Data Description and Previous Research\n",
    "# ==============================================================================\n",
    "\n",
    "# **Origin of the Data:**\n",
    "# The dataset is named `Tortoise.txt`. \n",
    "# (USER: Fill this part. Where did this dataset come from? What real-world system does it represent? \n",
    "# E.g., \"This dataset represents social interactions observed among a population of Gopher tortoises \n",
    "# (Gopherus polyphemus) at a specific research site over a defined period.\")\n",
    "\n",
    "# **Nodes and Edges Representation:**\n",
    "# *   **Nodes:** What do the integers (0, 1, 2, ...) represent? \n",
    "#     (USER: e.g., individual tortoises, specific locations, etc.)\n",
    "# *   **Edges:** What does a connection (edge) between two nodes signify? \n",
    "#     (USER: e.g., observed interaction, shared burrow, genetic relatedness, etc.) \n",
    "#     The edges in the file have a third column, which `nx.read_weighted_edgelist`\n",
    "#     interprets as a weight. In the provided example, all weights are '1', \n",
    "#     suggesting either an unweighted graph or that all interactions have a uniform weight/strength.\n",
    "\n",
    "# **Previous Research on the Network:**\n",
    "# (USER: This is a crucial part for your assignment. You need to search for literature \n",
    "# related to this specific dataset or similar types of networks. For example, if it's an \n",
    "# animal social network, you would look for papers on:)\n",
    "# *   *Studies using this specific dataset (if it's known).*\n",
    "# *   *General studies on social network analysis in [the specific animal species or context].*\n",
    "# *   *Commonly observed network structures or properties in such systems.*\n",
    "# *   *How network analysis has provided insights into the behavior, disease transmission, \n",
    "#      or conservation of the entities represented by the nodes.*\n",
    "\n",
    "# **Example (if it were a known dataset like Zachary's Karate Club):**\n",
    "# \"The Zachary's Karate Club network is a well-studied dataset representing friendships \n",
    "# between 34 members of a karate club at a US university in the 1970s. The network \n",
    "# famously split into two factions after a dispute. Research on this network often \n",
    "# focuses on community detection algorithms and predicting this split.\"\n",
    "\n",
    "# **For the Tortoise dataset, you might look for keywords like:**\n",
    "# *   \"Tortoise social network\"\n",
    "# *   \"Animal interaction network analysis\"\n",
    "# *   \"[Species name if known] network structure\"\n",
    "\n",
    "# (USER: Without more context on the `Tortoise.txt` origin, this section remains a template for you to fill.)\n",
    "\"\"\")\n",
    "print(\"\\n--- Data Description Section (Placeholder) Printed ---\")\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 5. BASIC STATISTICS OF YOUR NETWORK\n",
    "# ------------------------------------------------------------------------------\n",
    "print(\"\\n# ============================================================================== \")\n",
    "print(\"# 5. Basic Statistics of Your Network \")\n",
    "print(\"# ============================================================================== \")\n",
    "\n",
    "num_nodes = G.number_of_nodes()\n",
    "num_edges = G.number_of_edges()\n",
    "print(f\"Number of nodes (N): {num_nodes}\")\n",
    "print(f\"Number of edges (M): {num_edges}\")\n",
    "\n",
    "if num_nodes == 0:\n",
    "    print(\"Graph is empty. Cannot compute further statistics.\")\n",
    "    exit()\n",
    "\n",
    "density = nx.density(G)\n",
    "print(f\"Density of the graph: {density:.4f}\")\n",
    "\n",
    "degrees = [d for n, d in G.degree()]\n",
    "avg_degree = np.mean(degrees) if degrees else 0\n",
    "print(f\"Average degree: {avg_degree:.2f}\")\n",
    "print(f\"Minimum degree: {np.min(degrees) if degrees else 0}\")\n",
    "print(f\"Maximum degree: {np.max(degrees) if degrees else 0}\")\n",
    "\n",
    "is_connected_graph = nx.is_connected(G)\n",
    "print(f\"Is the graph connected? {is_connected_graph}\")\n",
    "\n",
    "num_components = 0\n",
    "avg_path_length_lcc = float('nan')\n",
    "diameter_lcc = float('nan')\n",
    "\n",
    "if not is_connected_graph:\n",
    "    num_components = nx.number_connected_components(G)\n",
    "    print(f\"Number of connected components: {num_components}\")\n",
    "    largest_cc_nodes = max(nx.connected_components(G), key=len)\n",
    "    LCC = G.subgraph(largest_cc_nodes).copy()\n",
    "    print(f\"Size of largest connected component (LCC): {LCC.number_of_nodes()} nodes, {LCC.number_of_edges()} edges\")\n",
    "    if LCC.number_of_nodes() > 1:\n",
    "        try:\n",
    "            avg_path_length_lcc = nx.average_shortest_path_length(LCC)\n",
    "            diameter_lcc = nx.diameter(LCC)\n",
    "        except nx.NetworkXError as e:\n",
    "            print(f\"Could not compute path metrics for LCC: {e}\")\n",
    "    else:\n",
    "        print(\"LCC is too small for path metrics.\")\n",
    "else:\n",
    "    LCC = G\n",
    "    print(\"The graph is connected, so LCC is the graph itself.\")\n",
    "    if LCC.number_of_nodes() > 1:\n",
    "        try:\n",
    "            avg_path_length_lcc = nx.average_shortest_path_length(LCC)\n",
    "            diameter_lcc = nx.diameter(LCC)\n",
    "        except nx.NetworkXError as e:\n",
    "            print(f\"Could not compute path metrics for LCC: {e}\")\n",
    "    else:\n",
    "        print(\"Graph is too small for path metrics.\")\n",
    "        \n",
    "print(f\"Average shortest path length (for LCC): {avg_path_length_lcc:.2f}\" if not np.isnan(avg_path_length_lcc) else \"Avg. Path Length (LCC): N/A\")\n",
    "print(f\"Diameter (for LCC): {diameter_lcc}\" if not np.isnan(diameter_lcc) else \"Diameter (LCC): N/A\")\n",
    "\n",
    "avg_clustering_coeff = nx.average_clustering(G)\n",
    "print(f\"Average clustering coefficient (global): {avg_clustering_coeff:.4f}\")\n",
    "\n",
    "transitivity = nx.transitivity(G)\n",
    "print(f\"Transitivity (global CC variant): {transitivity:.4f}\")\n",
    "\n",
    "is_bipartite_graph = nx.is_bipartite(G)\n",
    "print(f\"Is the graph bipartite? {is_bipartite_graph}\")\n",
    "if is_bipartite_graph:\n",
    "    bipartite_sets = nx.bipartite.sets(G)\n",
    "    print(f\"Bipartite sets (U, V): (Size {len(bipartite_sets[0])}, Size {len(bipartite_sets[1])})\")\n",
    "\n",
    "assortativity = nx.degree_assortativity_coefficient(G)\n",
    "print(f\"Degree assortativity coefficient: {assortativity:.4f}\")\n",
    "\n",
    "# Degree Distribution Plot\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.histplot(degrees, bins=max(1, int(np.sqrt(len(degrees)))), kde=True, color='dodgerblue', ec='black')\n",
    "plt.title('Degree Distribution of the Tortoise Network', fontsize=18)\n",
    "plt.xlabel('Degree', fontsize=14)\n",
    "plt.ylabel('Frequency of Nodes', fontsize=14)\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "save_current_plot(\"01_degree_distribution.png\")\n",
    "plt.show()\n",
    "\n",
    "stats_summary_df = pd.DataFrame({\n",
    "    'Metric': ['Nodes', 'Edges', 'Density', 'Average Degree', 'Min Degree', 'Max Degree', 'Connected?', \n",
    "               'Num. Components (if not connected)', 'Avg. Path Length (LCC)', 'Diameter (LCC)',\n",
    "               'Avg. Clustering Coeff.', 'Transitivity', 'Bipartite?', 'Assortativity'],\n",
    "    'Value': [num_nodes, num_edges, f\"{density:.4f}\", f\"{avg_degree:.2f}\", np.min(degrees) if degrees else 0, np.max(degrees) if degrees else 0, is_connected_graph,\n",
    "              num_components if not is_connected_graph else 'N/A', \n",
    "              f\"{avg_path_length_lcc:.2f}\" if not np.isnan(avg_path_length_lcc) else 'N/A',\n",
    "              diameter_lcc if not np.isnan(diameter_lcc) else 'N/A',\n",
    "              f\"{avg_clustering_coeff:.4f}\", f\"{transitivity:.4f}\", is_bipartite_graph, f\"{assortativity:.4f}\"]\n",
    "})\n",
    "print(\"\\n--- Summary Table of Basic Statistics ---\")\n",
    "print(stats_summary_df.to_string(index=False))\n",
    "print(\"\\n--- Basic Statistics Calculation Complete ---\")\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 6. CENTRALITY MEASURES (Illustrations of the five nodes of highest degree)\n",
    "# ------------------------------------------------------------------------------\n",
    "print(\"\\n# ============================================================================== \")\n",
    "print(\"# 6. Centrality Measures \")\n",
    "print(\"# ============================================================================== \")\n",
    "\n",
    "# 1. Degree Centrality (Classical)\n",
    "degree_centrality = nx.degree_centrality(G)\n",
    "sorted_degree_cent = sorted(degree_centrality.items(), key=lambda item: item[1], reverse=True)\n",
    "top5_degree = sorted_degree_cent[:5]\n",
    "\n",
    "# 2. Betweenness Centrality (Classical)\n",
    "betweenness_centrality = nx.betweenness_centrality(G, weight='weight') # Consider weights if meaningful\n",
    "sorted_betweenness_cent = sorted(betweenness_centrality.items(), key=lambda item: item[1], reverse=True)\n",
    "top5_betweenness = sorted_betweenness_cent[:5]\n",
    "\n",
    "# 3. Eigenvector Centrality (Spectral)\n",
    "# For Eigenvector centrality, graph must be connected for standard algorithm.\n",
    "# NetworkX handles disconnected graphs by computing for the largest component,\n",
    "# or returning 0 for nodes not in a component allowing eigenvector calculation.\n",
    "# It might fail to converge for some graphs.\n",
    "centrality_measure_name_3 = \"Eigenvector Centrality (Spectral)\"\n",
    "try:\n",
    "    eigenvector_centrality = nx.eigenvector_centrality_numpy(G, weight='weight') # Using numpy version for stability\n",
    "    sorted_eigenvector_cent = sorted(eigenvector_centrality.items(), key=lambda item: item[1], reverse=True)\n",
    "    top5_eigenvector = sorted_eigenvector_cent[:5]\n",
    "except (nx.NetworkXError, nx.PowerIterationFailedConvergence) as e:\n",
    "    print(f\"Eigenvector centrality failed: {e}. Using PageRank as an alternative spectral measure.\")\n",
    "    pagerank_centrality = nx.pagerank(G, weight='weight')\n",
    "    sorted_pagerank_cent = sorted(pagerank_centrality.items(), key=lambda item: item[1], reverse=True)\n",
    "    top5_eigenvector = sorted_pagerank_cent[:5] # Using the same variable name for top5 for consistency\n",
    "    eigenvector_centrality = pagerank_centrality # Use PageRank values\n",
    "    centrality_measure_name_3 = \"PageRank Centrality (Spectral Alt.)\"\n",
    "\n",
    "# 4. Closeness Centrality (Classical)\n",
    "closeness_centrality = nx.closeness_centrality(G, distance='weight') # distance if weights are path lengths\n",
    "sorted_closeness_cent = sorted(closeness_centrality.items(), key=lambda item: item[1], reverse=True)\n",
    "top5_closeness = sorted_closeness_cent[:5]\n",
    "\n",
    "print(\"--- Top 5 Nodes by Centrality Measures ---\")\n",
    "print(f\"Top 5 by Degree Centrality: {top5_degree}\")\n",
    "print(f\"Top 5 by Betweenness Centrality: {top5_betweenness}\")\n",
    "print(f\"Top 5 by {centrality_measure_name_3}: {top5_eigenvector}\")\n",
    "print(f\"Top 5 by Closeness Centrality: {top5_closeness}\")\n",
    "\n",
    "# Create a DataFrame for easier comparison\n",
    "centrality_data = {\n",
    "    'Node': list(G.nodes()),\n",
    "    'Degree_Cent': [degree_centrality.get(n, 0) for n in G.nodes()],\n",
    "    'Betweenness_Cent': [betweenness_centrality.get(n, 0) for n in G.nodes()],\n",
    "    centrality_measure_name_3.split(' ')[0] + '_Cent': [eigenvector_centrality.get(n, 0) for n in G.nodes()],\n",
    "    'Closeness_Cent': [closeness_centrality.get(n, 0) for n in G.nodes()]\n",
    "}\n",
    "centrality_df = pd.DataFrame(centrality_data).set_index('Node').sort_values(by='Degree_Cent', ascending=False)\n",
    "print(\"\\n--- Centrality Values for Top Nodes (Sorted by Degree Centrality) ---\")\n",
    "print(centrality_df.head(10).to_string(float_format=\"%.4f\"))\n",
    "\n",
    "# Plotting Centrality Distributions\n",
    "fig_cent_dist, axes_cent_dist = plt.subplots(2, 2, figsize=(18, 14))\n",
    "fig_cent_dist.suptitle('Distributions of Centrality Measures', fontsize=22, y=0.98)\n",
    "\n",
    "sns.histplot(centrality_df['Degree_Cent'], bins=15, kde=True, ax=axes_cent_dist[0, 0], color='cornflowerblue', ec='black')\n",
    "axes_cent_dist[0, 0].set_title('Degree Centrality')\n",
    "sns.histplot(centrality_df['Betweenness_Cent'], bins=15, kde=True, ax=axes_cent_dist[0, 1], color='salmon', ec='black')\n",
    "axes_cent_dist[0, 1].set_title('Betweenness Centrality')\n",
    "if centrality_df['Betweenness_Cent'].max() > 0 and centrality_df['Betweenness_Cent'].min() >= 0 and centrality_df['Betweenness_Cent'].skew() > 2:\n",
    "    axes_cent_dist[0, 1].set_yscale('log')\n",
    "    axes_cent_dist[0, 1].set_ylabel('Frequency (Log Scale)')\n",
    "\n",
    "\n",
    "sns.histplot(centrality_df[centrality_measure_name_3.split(' ')[0] + '_Cent'], bins=15, kde=True, ax=axes_cent_dist[1, 0], color='mediumseagreen', ec='black')\n",
    "axes_cent_dist[1, 0].set_title(centrality_measure_name_3)\n",
    "sns.histplot(centrality_df['Closeness_Cent'], bins=15, kde=True, ax=axes_cent_dist[1, 1], color='gold', ec='black')\n",
    "axes_cent_dist[1, 1].set_title('Closeness Centrality')\n",
    "\n",
    "for ax_row in axes_cent_dist:\n",
    "    for ax in ax_row:\n",
    "        ax.set_xlabel('Centrality Value')\n",
    "        if not (ax == axes_cent_dist[0,1] and centrality_df['Betweenness_Cent'].skew() > 2) : # Avoid double labeling if log scale\n",
    "             ax.set_ylabel('Frequency')\n",
    "        ax.grid(True, linestyle=':', alpha=0.6)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "save_current_plot(\"02_centrality_distributions.png\")\n",
    "plt.show()\n",
    "\n",
    "# Visualization of Top Nodes in the Network (Nodes colored by centrality score)\n",
    "fig_cent_color, axes_cent_color = plt.subplots(2, 2, figsize=(22, 20)) # Larger figure\n",
    "fig_cent_color.suptitle('Network: Nodes Colored by Centrality Score', fontsize=24, y=0.98)\n",
    "all_nodes_list_sorted = sorted(list(G.nodes())) # Consistent node ordering\n",
    "\n",
    "# Helper lists for labeling specific top nodes\n",
    "top5_degree_nodes_only = [n for n,_ in top5_degree]\n",
    "top5_betweenness_nodes_only = [n for n,_ in top5_betweenness]\n",
    "top5_eigenvector_nodes_only = [n for n,_ in top5_eigenvector]\n",
    "top5_closeness_nodes_only = [n for n,_ in top5_closeness]\n",
    "all_top_nodes = set(top5_degree_nodes_only + top5_betweenness_nodes_only + top5_eigenvector_nodes_only + top5_closeness_nodes_only)\n",
    "\n",
    "# Function to draw a centrality-colored graph\n",
    "def draw_centrality_graph(ax, G_graph, pos_layout, centrality_values_dict, cmap_color, title, label_nodes, centrality_label):\n",
    "    node_values = [centrality_values_dict.get(node, 0) for node in all_nodes_list_sorted]\n",
    "    max_val = max(node_values) if node_values else 1\n",
    "    min_val = min(node_values) if node_values else 0\n",
    "    \n",
    "    node_sizes = [val * 5000 / (max_val if max_val >0 else 1) + 100 for val in node_values] # Dynamic sizing\n",
    "    if not node_values or max_val == 0: # Handle cases with all zero centrality\n",
    "        node_sizes = [150 for _ in node_values]\n",
    "\n",
    "    nx.draw_networkx_nodes(G_graph, pos_layout, nodelist=all_nodes_list_sorted, node_color=node_values, \n",
    "                           cmap=cmap_color, node_size=node_sizes, ax=ax, alpha=0.85, edgecolors='grey', linewidths=0.5)\n",
    "    nx.draw_networkx_edges(G_graph, pos_layout, ax=ax, alpha=0.25, edge_color='darkgray', width=1.0)\n",
    "    nx.draw_networkx_labels(G_graph, pos_layout, ax=ax, font_size=9, font_weight='bold',\n",
    "                            labels={n:n for n in label_nodes if n in G_graph}) # Label only specified nodes\n",
    "    \n",
    "    ax.set_title(title, fontsize=18)\n",
    "    ax.axis('off')\n",
    "    # Colorbar\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap_color, norm=plt.Normalize(vmin=min_val, vmax=max_val if max_val > min_val else min_val + 1e-9)) # Avoid vmin=vmax\n",
    "    sm.set_array([])\n",
    "    cbar = fig_cent_color.colorbar(sm, ax=ax, orientation='vertical', fraction=0.046, pad=0.04, shrink=0.8)\n",
    "    cbar.set_label(centrality_label, fontsize=12)\n",
    "\n",
    "draw_centrality_graph(axes_cent_color[0,0], G, pos_spring, degree_centrality, plt.cm.viridis, 'Degree Centrality', top5_degree_nodes_only, 'Degree Centrality')\n",
    "draw_centrality_graph(axes_cent_color[0,1], G, pos_spring, betweenness_centrality, plt.cm.plasma, 'Betweenness Centrality', top5_betweenness_nodes_only, 'Betweenness Centrality')\n",
    "draw_centrality_graph(axes_cent_color[1,0], G, pos_spring, eigenvector_centrality, plt.cm.cividis, centrality_measure_name_3, top5_eigenvector_nodes_only, centrality_measure_name_3)\n",
    "draw_centrality_graph(axes_cent_color[1,1], G, pos_spring, closeness_centrality, plt.cm.magma, 'Closeness Centrality', top5_closeness_nodes_only, 'Closeness Centrality')\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "save_current_plot(\"03_centrality_colored_graphs.png\")\n",
    "plt.show()\n",
    "\n",
    "print(\"--- Centrality Analysis and Visualization Complete ---\")\n",
    "print(\"\"\"\n",
    "--- Discussion on Centrality Similarities/Differences (USER: Adapt this based on your results!) ---\n",
    "- Degree centrality identifies nodes with many direct connections (local influence).\n",
    "- Betweenness centrality identifies \"bridge\" nodes crucial for flow between network parts.\n",
    "- Eigenvector/PageRank centrality identifies nodes connected to other influential nodes (global influence).\n",
    "- Closeness centrality identifies nodes that can reach others quickly on average.\n",
    "\n",
    "Observe which nodes appear in multiple top-5 lists. For example:\n",
    "  'Node X is high in both degree and betweenness, suggesting it's a local hub AND a critical connector.'\n",
    "  'Node Y is high in eigenvector centrality but not necessarily degree, indicating it's connected to other influential nodes rather than just many nodes.'\n",
    "  'Node Z might be high in closeness, making it efficient for spreading information, but not a major hub by degree.'\n",
    "\"\"\")\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 7. RELATIVE ABUNDANCE OF SUBGRAPHS (MOTIFS)\n",
    "# ------------------------------------------------------------------------------\n",
    "print(\"\\n# ============================================================================== \")\n",
    "print(\"# 7. Relative Abundance of Subgraphs (Motifs) \")\n",
    "print(\"# ============================================================================== \")\n",
    "# The assignment mentions \"you will be provided with some code to compute this\".\n",
    "# If specific code is provided, use that. Here, we count triangles.\n",
    "\n",
    "num_triangles_per_node = nx.triangles(G)\n",
    "total_triangles = sum(num_triangles_per_node.values()) // 3\n",
    "print(f\"Total number of triangles in the graph: {total_triangles}\")\n",
    "\n",
    "if total_triangles > 0:\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.histplot(list(num_triangles_per_node.values()), \n",
    "                 bins=max(1, max(num_triangles_per_node.values()) if num_triangles_per_node else 1), \n",
    "                 kde=False, color='teal', ec='black')\n",
    "    plt.title('Distribution of Triangles per Node', fontsize=18)\n",
    "    plt.xlabel('Number of Triangles Node is Part Of', fontsize=14)\n",
    "    plt.ylabel('Frequency of Nodes', fontsize=14)\n",
    "    if num_triangles_per_node and max(num_triangles_per_node.values()) > 20 : plt.yscale('log')\n",
    "    plt.grid(True, linestyle=':', alpha=0.6)\n",
    "    save_current_plot(\"04_triangle_distribution.png\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No triangles found in the graph.\")\n",
    "\n",
    "print(\"\"\"\n",
    "--- Interpretation of Subgraph (Triangle) Analysis ---\n",
    "Triangles are the simplest form of a cluster. A high number of triangles often correlates \n",
    "with a high clustering coefficient, indicating local dense connectivity. This can be compared \n",
    "to random graph models. If the real network has significantly more triangles than a random \n",
    "graph of similar size/density, it suggests non-random structuring (e.g., due to triadic closure).\n",
    "\n",
    "(USER: If provided with specific code for other motifs, integrate it here and discuss \n",
    "over/under-representation compared to random networks.)\n",
    "\"\"\")\n",
    "print(\"\\n--- Subgraph Analysis Complete ---\")\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 8. COMMUNITY STRUCTURE WITHIN YOUR NETWORK\n",
    "# ------------------------------------------------------------------------------\n",
    "print(\"\\n# ============================================================================== \")\n",
    "print(\"# 8. Community Structure \")\n",
    "print(\"# ============================================================================== \")\n",
    "\n",
    "communities = None\n",
    "partition = None\n",
    "modularity_score = float('nan')\n",
    "num_communities = 0\n",
    "\n",
    "if G.number_of_nodes() == 0 or G.number_of_edges() == 0:\n",
    "    print(\"Graph is empty or has no edges. Cannot perform community detection.\")\n",
    "else:\n",
    "    try:\n",
    "        partition = community_louvain.best_partition(G, weight='weight', random_state=42)\n",
    "        modularity_score = community_louvain.modularity(partition, G, weight='weight')\n",
    "        num_communities = len(set(partition.values()))\n",
    "        \n",
    "        print(f\"Detected {num_communities} communities using the Louvain algorithm.\")\n",
    "        print(f\"Modularity of the partition: {modularity_score:.4f} (Higher is better, typically 0.3-0.7 indicates good structure)\")\n",
    "\n",
    "        community_counts = Counter(partition.values())\n",
    "        print(\"\\nCommunity sizes (Top 10 largest):\")\n",
    "        for comm_id, count in sorted(community_counts.items(), key=lambda item: item[1], reverse=True)[:10]:\n",
    "            print(f\"  Community {comm_id}: {count} nodes\")\n",
    "\n",
    "        communities = [[] for _ in range(num_communities)]\n",
    "        for node, comm_id in partition.items():\n",
    "            communities[comm_id].append(node) # communities is a list of lists of nodes\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during community detection: {e}\")\n",
    "\n",
    "if partition and num_communities > 0:\n",
    "    plt.figure(figsize=(12, 7))\n",
    "    comm_ids_sorted = sorted(community_counts, key=community_counts.get, reverse=True)\n",
    "    sns.barplot(x=[str(c) for c in comm_ids_sorted], \n",
    "                y=[community_counts[c] for c in comm_ids_sorted],\n",
    "                palette=\"viridis_r\") # Use a nice color palette\n",
    "    plt.title('Distribution of Community Sizes', fontsize=18)\n",
    "    plt.xlabel('Community ID (Sorted by Size)', fontsize=14)\n",
    "    plt.ylabel('Number of Nodes', fontsize=14)\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.tight_layout()\n",
    "    save_current_plot(\"05_community_size_distribution.png\")\n",
    "    plt.show()\n",
    "\n",
    "    # Visualize the graph with nodes colored by community\n",
    "    plt.figure(figsize=(18, 18)) # Very large figure for clear community plot\n",
    "    pos_comm_viz = nx.spring_layout(G, k=0.8, iterations=70, seed=42, weight='weight') # Layout sensitive to communities\n",
    "\n",
    "    # Generate a color for each community\n",
    "    if num_communities <= 10:\n",
    "        unique_colors = plt.cm.get_cmap('tab10', num_communities)\n",
    "    elif num_communities <=20:\n",
    "        unique_colors = plt.cm.get_cmap('tab20', num_communities)\n",
    "    else: \n",
    "        # For many communities, tableau and CSS colors might not be enough or distinct enough in some colormaps\n",
    "        # Using a perceptually uniform colormap like 'viridis' and sampling from it\n",
    "        # Or generate a list of distinguishable colors\n",
    "        hsv_tuples = [(x * 1.0 / num_communities, 0.7, 0.9) for x in range(num_communities)]\n",
    "        unique_colors_list = [mcolors.hsv_to_rgb(x) for x in hsv_tuples]\n",
    "        unique_colors = mcolors.ListedColormap(unique_colors_list)\n",
    "\n",
    "\n",
    "    node_colors_community = [unique_colors(partition[node] % unique_colors.N) for node in G.nodes()] # Modulo N for safety with colormaps\n",
    "\n",
    "    nx.draw_networkx_nodes(G, pos_comm_viz, node_color=node_colors_community, \n",
    "                           node_size=250, alpha=0.9, edgecolors='black', linewidths=0.5)\n",
    "    \n",
    "    edge_colors_community = []\n",
    "    edge_widths_community = []\n",
    "    for u, v in G.edges():\n",
    "        if partition[u] == partition[v]: # Intra-community edge\n",
    "            edge_colors_community.append(unique_colors(partition[u] % unique_colors.N))\n",
    "            edge_widths_community.append(1.5) # Thicker for intra\n",
    "        else: # Inter-community edge\n",
    "            edge_colors_community.append('lightgrey') \n",
    "            edge_widths_community.append(0.5) # Thinner for inter\n",
    "            \n",
    "    nx.draw_networkx_edges(G, pos_comm_viz, width=edge_widths_community, alpha=0.6, edge_color=edge_colors_community)\n",
    "    nx.draw_networkx_labels(G, pos_comm_viz, font_size=9, font_weight='bold')\n",
    "\n",
    "    plt.title(f'Network Communities (Louvain Algorithm, Modularity: {modularity_score:.3f})', fontsize=22)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    if 1 < num_communities <= 10: # Manageable legend\n",
    "        legend_handles_comm = [plt.Line2D([0], [0], marker='o', color='w', \n",
    "                                          label=f'Comm {i} ({community_counts[i]} nodes)',\n",
    "                                          markersize=12, markerfacecolor=unique_colors(i % unique_colors.N))\n",
    "                               for i in sorted(community_counts.keys())[:num_communities]] # Show for sorted comm IDs\n",
    "        plt.legend(handles=legend_handles_comm, loc='best', title=\"Communities\", fontsize=11, frameon=True, fancybox=True, shadow=True)\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    save_current_plot(\"06_network_communities_visualization.png\")\n",
    "    plt.show()\n",
    "\n",
    "    # Detailed Community Statistics\n",
    "    print(\"\\n--- Detailed Community Statistics ---\")\n",
    "    community_details_list = []\n",
    "    for i in range(num_communities):\n",
    "        comm_nodes = [node for node, comm_id in partition.items() if comm_id == i]\n",
    "        if not comm_nodes: continue\n",
    "\n",
    "        subgraph = G.subgraph(comm_nodes)\n",
    "        comm_density = nx.density(subgraph)\n",
    "        internal_edges = subgraph.number_of_edges()\n",
    "        \n",
    "        external_edges = 0\n",
    "        boundary_nodes = set()\n",
    "        for node_in_comm in comm_nodes:\n",
    "            for neighbor in G.neighbors(node_in_comm):\n",
    "                if partition.get(neighbor) != i: # Use .get for safety if a neighbor somehow isn't in partition\n",
    "                    external_edges += 1\n",
    "                    boundary_nodes.add(node_in_comm)\n",
    "        \n",
    "        comm_avg_degree_internal = (2 * internal_edges) / len(comm_nodes) if len(comm_nodes) > 0 else 0\n",
    "        \n",
    "        details = {\n",
    "            \"Comm_ID\": i, \"Nodes\": len(comm_nodes), \"Internal_Edges\": internal_edges,\n",
    "            \"Density\": f\"{comm_density:.3f}\", \"External_Edges_Count\": external_edges, # Sum of edges leaving\n",
    "            \"Boundary_Nodes\": len(boundary_nodes), \"Avg_Internal_Deg\": f\"{comm_avg_degree_internal:.2f}\"\n",
    "        }\n",
    "        community_details_list.append(details)\n",
    "\n",
    "    community_details_df = pd.DataFrame(community_details_list).sort_values(by=\"Nodes\", ascending=False)\n",
    "    print(community_details_df.to_string(index=False))\n",
    "    \n",
    "    if not centrality_df.empty:\n",
    "        centrality_df['Community'] = centrality_df.index.map(partition.get)\n",
    "        # Ensure 'Community' column is not NaN before grouping for robustness\n",
    "        community_centrality_summary = centrality_df.dropna(subset=['Community']).groupby('Community').mean()\n",
    "        print(\"\\n--- Average Centrality Scores per Community ---\")\n",
    "        print(community_centrality_summary.to_string(float_format=\"%.3f\"))\n",
    "        \n",
    "        if not community_centrality_summary.empty:\n",
    "            community_centrality_summary.plot(kind='bar', figsize=(15,8), colormap='Spectral', edgecolor='black')\n",
    "            plt.title('Average Centrality Scores by Community', fontsize=18)\n",
    "            plt.ylabel('Average Centrality Value', fontsize=14)\n",
    "            plt.xlabel('Community ID', fontsize=14)\n",
    "            plt.xticks(rotation=0)\n",
    "            plt.legend(title='Centrality Type', bbox_to_anchor=(1.02, 1), loc='upper left')\n",
    "            plt.tight_layout(rect=[0,0,0.85,1]) # Adjust for legend\n",
    "            save_current_plot(\"07_avg_centrality_per_community.png\")\n",
    "            plt.show()\n",
    "else:\n",
    "    print(\"Skipping detailed community analysis as no communities were found or an error occurred.\")\n",
    "print(\"\\n--- Community Detection and Analysis Complete ---\")\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 9. ANOTHER ASPECT OF NETWORK ANALYSIS (Originality will be rewarded)\n",
    "#    Choosing K-Core Decomposition for this example.\n",
    "# ------------------------------------------------------------------------------\n",
    "print(\"\\n# ============================================================================== \")\n",
    "print(\"# 9. Another Aspect of Network Analysis: K-Core Decomposition \")\n",
    "print(\"# ============================================================================== \")\n",
    "\n",
    "if G.number_of_nodes() > 0:\n",
    "    core_numbers = nx.core_number(G)\n",
    "    max_core = 0\n",
    "    if core_numbers:\n",
    "        max_core = max(core_numbers.values())\n",
    "        print(f\"Maximum k-core number (main coreness): {max_core}\")\n",
    "\n",
    "        core_counts = Counter(core_numbers.values())\n",
    "        plt.figure(figsize=(10, 7))\n",
    "        sns.barplot(x=list(core_counts.keys()), y=list(core_counts.values()),\n",
    "                    order=sorted(core_counts.keys()), palette=\"coolwarm_r\", ec='black')\n",
    "        plt.title('Distribution of Node Core Numbers', fontsize=18)\n",
    "        plt.xlabel('Core Number (k)', fontsize=14)\n",
    "        plt.ylabel('Number of Nodes', fontsize=14)\n",
    "        plt.grid(True, linestyle=':', alpha=0.6)\n",
    "        save_current_plot(\"08_k_core_distribution.png\")\n",
    "        plt.show()\n",
    "\n",
    "        if max_core > 0:\n",
    "            # Visualize nodes colored by core number\n",
    "            plt.figure(figsize=(15,15))\n",
    "            node_colors_kcore = [plt.cm.coolwarm_r(core_numbers.get(node,0) / max_core if max_core > 0 else 0) for node in G.nodes()]\n",
    "            nx.draw_networkx_nodes(G, pos_spring, node_color=node_colors_kcore, node_size=200, alpha=0.9, edgecolors='grey')\n",
    "            nx.draw_networkx_edges(G, pos_spring, width=1.0, alpha=0.3, edge_color='darkgray')\n",
    "            nx.draw_networkx_labels(G, pos_spring, font_size=9)\n",
    "            \n",
    "            plt.title(f'Network Nodes Colored by K-Core Number (Max Core: {max_core})', fontsize=20)\n",
    "            # Add colorbar for k-core\n",
    "            sm_kcore = plt.cm.ScalarMappable(cmap=plt.cm.coolwarm_r, norm=plt.Normalize(vmin=0, vmax=max_core))\n",
    "            sm_kcore.set_array([])\n",
    "            cbar_kcore = plt.colorbar(sm_kcore, ax=plt.gca(), orientation='vertical', fraction=0.046, pad=0.04, ticks=range(0,max_core+1), shrink=0.8)\n",
    "            cbar_kcore.set_label('Core Number (k)', fontsize=12)\n",
    "            plt.axis('off')\n",
    "            save_current_plot(\"09_nodes_colored_by_kcore.png\")\n",
    "            plt.show()\n",
    "            \n",
    "            main_core_nodes = [node for node, c_num in core_numbers.items() if c_num == max_core]\n",
    "            print(f\"Nodes in the {max_core}-core (most central cohesive group): {sorted(main_core_nodes)}\")\n",
    "        else:\n",
    "            print(\"No significant cores (max_core = 0). The graph might be very sparse or tree-like.\")\n",
    "    else:\n",
    "        print(\"Could not compute core numbers (e.g., empty graph).\")\n",
    "else:\n",
    "    print(\"Graph is empty, skipping K-core decomposition.\")\n",
    "\n",
    "print(\"\"\"\n",
    "--- Interpretation of K-Core Decomposition ---\n",
    "K-core decomposition identifies hierarchically nested groups of nodes based on their minimum \n",
    "degree within a subgraph. The innermost core (highest k) represents the most densely and \n",
    "resiliently connected part of the network. Nodes with higher core numbers are more central \n",
    "in terms of network cohesion and are less likely to be disconnected if other nodes are removed.\n",
    "This can reveal the backbone or nucleus of the network.\n",
    "\"\"\")\n",
    "print(\"\\n--- K-Core Analysis Complete ---\")\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 10. COMPARISON WITH RANDOM GRAPH MODELS\n",
    "# ------------------------------------------------------------------------------\n",
    "print(\"\\n# ============================================================================== \")\n",
    "print(\"# 10. Comparison with Random Graph Models \")\n",
    "print(\"# ============================================================================== \")\n",
    "\n",
    "if N == 0:\n",
    "    print(\"Original graph is empty, cannot generate random models.\")\n",
    "else:\n",
    "    # Erdos-Renyi G(N,M) model\n",
    "    gnm = nx.gnm_random_graph(N, M, seed=42)\n",
    "    gnm_avg_clust = nx.average_clustering(gnm)\n",
    "    gnm_avg_path = nx.average_shortest_path_length(max(nx.connected_components(gnm), key=len) if not nx.is_connected(gnm) else gnm) if gnm.number_of_nodes() > 1 else float('nan')\n",
    "\n",
    "    # Erdos-Renyi G(N,p) model\n",
    "    p_er = density \n",
    "    gnp = nx.erdos_renyi_graph(N, p_er, seed=42)\n",
    "    gnp_avg_clust = nx.average_clustering(gnp)\n",
    "    gnp_avg_path = nx.average_shortest_path_length(max(nx.connected_components(gnp), key=len) if not nx.is_connected(gnp) else gnp) if gnp.number_of_nodes() > 1 else float('nan')\n",
    "\n",
    "    # Configuration Model (CM)\n",
    "    cm = None\n",
    "    cm_avg_clust = float('nan')\n",
    "    cm_avg_path = float('nan')\n",
    "    if sum(degrees) % 2 == 0 and degrees: # Check for valid degree sequence\n",
    "        try:\n",
    "            cm = nx.configuration_model(degrees, seed=42)\n",
    "            cm = nx.Graph(cm) # Remove parallel edges and self-loops\n",
    "            cm.remove_edges_from(nx.selfloop_edges(cm))\n",
    "            cm_avg_clust = nx.average_clustering(cm)\n",
    "            if cm.number_of_nodes() > 0 and cm.number_of_edges() > 0: # Check if CM is not empty\n",
    "                 cm_avg_path = nx.average_shortest_path_length(max(nx.connected_components(cm), key=len, default=set()) if not nx.is_connected(cm) else cm) if cm.number_of_nodes() > 1 else float('nan')\n",
    "            else: # CM became empty after simplification\n",
    "                cm_avg_path = float('nan')\n",
    "        except nx.NetworkXError as e_cm:\n",
    "            print(f\"   Error generating/processing Configuration Model: {e_cm}\")\n",
    "    else:\n",
    "        print(\"Configuration model cannot be generated (e.g. odd degree sum or empty degree list).\")\n",
    "\n",
    "\n",
    "    comparison_data = {\n",
    "        'Metric': ['Avg. Clustering Coeff.', 'Avg. Shortest Path (LCC/Largest)'],\n",
    "        'Real Network (G)': [f\"{avg_clustering_coeff:.4f}\", f\"{avg_path_length_lcc:.2f}\" if not np.isnan(avg_path_length_lcc) else \"N/A\"],\n",
    "        'G(N,M) Model': [f\"{gnm_avg_clust:.4f}\", f\"{gnm_avg_path:.2f}\" if not np.isnan(gnm_avg_path) else \"N/A\"],\n",
    "        'G(N,p) Model': [f\"{gnp_avg_clust:.4f}\", f\"{gnp_avg_path:.2f}\" if not np.isnan(gnp_avg_path) else \"N/A\"],\n",
    "        'Config. Model (CM)': [f\"{cm_avg_clust:.4f}\" if cm and not np.isnan(cm_avg_clust) else \"N/A\", \n",
    "                               f\"{cm_avg_path:.2f}\" if cm and not np.isnan(cm_avg_path) else \"N/A\"]\n",
    "    }\n",
    "    comparison_df = pd.DataFrame(comparison_data)\n",
    "    print(\"\\n--- Random Model Comparison Summary Table ---\")\n",
    "    print(comparison_df.to_string(index=False))\n",
    "\n",
    "    # Plot Degree Distributions for comparison\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    sns.histplot(degrees, color=\"red\", label=f'Real Network (Avg: {avg_degree:.2f})', kde=False, stat=\"density\", element=\"step\", fill=False, linewidth=2.5)\n",
    "    sns.histplot([d for n, d in gnm.degree()], color=\"blue\", label=f'G(N,M) Model (Avg: {np.mean([d for n,d in gnm.degree()]):.2f})', kde=False, stat=\"density\", element=\"step\", fill=False, linewidth=1.5, linestyle='--')\n",
    "    sns.histplot([d for n, d in gnp.degree()], color=\"green\", label=f'G(N,p) Model (Avg: {np.mean([d for n,d in gnp.degree()]):.2f})', kde=False, stat=\"density\", element=\"step\", fill=False, linewidth=1.5, linestyle=':')\n",
    "    if cm:\n",
    "        cm_degrees = [d for n,d in cm.degree()]\n",
    "        sns.histplot(cm_degrees, color=\"purple\", label=f'Config. Model (Avg: {np.mean(cm_degrees):.2f})', kde=False, stat=\"density\", element=\"step\", fill=False, linewidth=1.5, linestyle='-.')\n",
    "\n",
    "    plt.title('Comparison of Degree Distributions with Random Models', fontsize=20)\n",
    "    plt.xlabel('Degree', fontsize=16)\n",
    "    plt.ylabel('Density (Normalized Frequency)', fontsize=16)\n",
    "    plt.legend(fontsize=12, loc='upper right', frameon=True, fancybox=True, shadow=True)\n",
    "    plt.grid(True, linestyle=':', alpha=0.6)\n",
    "    # Consider log scales if distributions are very skewed\n",
    "    # plt.xscale('log')\n",
    "    # plt.yscale('log')\n",
    "    save_current_plot(\"10_degree_dist_comparison_random_models.png\")\n",
    "    plt.show()\n",
    "\n",
    "print(\"\"\"\n",
    "--- Discussion on Comparison with Random Models ---\n",
    "- Clustering Coefficient: Real-world networks often have higher clustering than G(N,M) or G(N,p). \n",
    "  The Configuration Model, by preserving degrees, might get closer but still often underestimates it \n",
    "  if there's true community structure or triadic closure beyond degree effects.\n",
    "  (USER: Compare your G's clustering coeff: {avg_clustering_coeff:.4f} with the models.)\n",
    "\n",
    "- Average Path Length: Real networks often exhibit the \"small-world\" property (short average paths), \n",
    "  comparable to or slightly larger than random graphs.\n",
    "  (USER: Compare your G's LCC path length: {avg_path_length_lcc:.2f} with the models.)\n",
    "\n",
    "- Degree Distribution: Erdos-Renyi graphs typically have a Poisson-like degree distribution. \n",
    "  If the real network shows a power-law or heavy-tailed distribution, it will differ. The \n",
    "  Configuration Model should match the real network's degree distribution by design.\n",
    "  (USER: Observe the plot and comment on similarities/differences.)\n",
    "\"\"\".format(avg_clustering_coeff=avg_clustering_coeff, avg_path_length_lcc=avg_path_length_lcc if not np.isnan(avg_path_length_lcc) else 0))\n",
    "print(\"\\n--- Random Model Comparison Complete ---\")\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 11. DASHBOARD / SUMMARY OF FINDINGS\n",
    "# ------------------------------------------------------------------------------\n",
    "print(\"\\n# ============================================================================== \")\n",
    "print(\"# 11. Dashboard / Summary of Findings \")\n",
    "print(\"# ============================================================================== \")\n",
    "\n",
    "fig_dashboard, axs_dashboard = plt.subplots(2, 2, figsize=(24, 18)) # Large dashboard\n",
    "fig_dashboard.suptitle(\"Tortoise Network Analysis: Key Insights Dashboard\", fontsize=28, y=0.98)\n",
    "\n",
    "# Panel 1: Basic Stats & Network Plot with Communities\n",
    "ax_dash1 = axs_dashboard[0,0]\n",
    "if partition and num_communities > 0 and 'unique_colors' in locals() and 'pos_comm_viz' in locals():\n",
    "    node_colors_comm_dash = [unique_colors(partition[node] % unique_colors.N) for node in G.nodes()]\n",
    "    edge_colors_dash = [unique_colors(partition[u] % unique_colors.N) if partition[u] == partition[v] else 'lightgray' for u, v in G.edges()]\n",
    "    nx.draw_networkx_nodes(G, pos_comm_viz, node_color=node_colors_comm_dash, node_size=100, alpha=0.8, ax=ax_dash1, edgecolors='grey')\n",
    "    nx.draw_networkx_edges(G, pos_comm_viz, edge_color=edge_colors_dash, width=0.7, alpha=0.5, ax=ax_dash1)\n",
    "    ax_dash1.set_title(f'Network Structure & Communities ({num_communities} found, Modularity {modularity_score:.3f})', fontsize=18)\n",
    "else:\n",
    "    nx.draw_networkx(G, pos_spring, node_size=100, alpha=0.8, ax=ax_dash1, with_labels=True, font_size=8, width=0.7, node_color='skyblue', edge_color='gray')\n",
    "    ax_dash1.set_title('Network Structure Overview', fontsize=18)\n",
    "ax_dash1.axis('off')\n",
    "stats_text = (f\"Nodes: {num_nodes}, Edges: {num_edges}\\nAvg. Degree: {avg_degree:.2f}, Density: {density:.4f}\\n\"\n",
    "              f\"Avg. Clustering: {avg_clustering_coeff:.4f}\\nAvg. Path (LCC): {avg_path_length_lcc:.2f}\" if not np.isnan(avg_path_length_lcc) else \"Avg. Path (LCC): N/A\")\n",
    "ax_dash1.text(0.01, 0.01, stats_text, transform=ax_dash1.transAxes, fontsize=11,\n",
    "              verticalalignment='bottom', bbox=dict(boxstyle='round,pad=0.5', fc='wheat', alpha=0.4))\n",
    "\n",
    "# Panel 2: Centrality Highlights (e.g., Degree Distribution & Top Nodes)\n",
    "ax_dash2 = axs_dashboard[0,1]\n",
    "sns.histplot(degrees, bins=15, kde=True, ax=ax_dash2, color='mediumpurple', ec='black')\n",
    "ax_dash2.set_title('Degree Distribution & Key Central Nodes', fontsize=18)\n",
    "ax_dash2.set_xlabel('Degree', fontsize=14)\n",
    "ax_dash2.set_ylabel('Frequency', fontsize=14)\n",
    "top_deg_str = \", \".join([str(n) for n,c in top5_degree[:3]])\n",
    "top_bet_str = \", \".join([str(n) for n,c in top5_betweenness[:3]])\n",
    "central_nodes_text = (f\"Top Degree: {top_deg_str}...\\n\"\n",
    "                      f\"Top Betweenness: {top_bet_str}...\")\n",
    "ax_dash2.text(0.98, 0.98, central_nodes_text, transform=ax_dash2.transAxes, fontsize=11,\n",
    "              ha='right', va='top', bbox=dict(boxstyle='round,pad=0.5', fc='aliceblue', alpha=0.6))\n",
    "ax_dash2.grid(True, linestyle=':', alpha=0.5)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sage"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [5], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinalg\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mlg\u001b[39;00m \u001b[38;5;66;03m# For matrix operations if needed, though NetworkX handles most\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Counter\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcommunity\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mcommunity_louvain\u001b[39;00m \u001b[38;5;66;03m# For Louvain community detection\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sage"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SageMath 9.5",
   "language": "sage",
   "name": "sagemath"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
